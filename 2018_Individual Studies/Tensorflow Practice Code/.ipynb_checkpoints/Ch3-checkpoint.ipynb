{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 텐서와 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Tensorflow as name 'tf'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "### Constant Variable\n",
    "hello = tf.constant('Hello, Tensorflow!')\n",
    "\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수 hello가 Tensor라는 변수 type을 가지며, Constant를 담고 있다. Tensor는 가장 기본적이고 중요한 자료형이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank, Shape 개념\n",
    "* Rank는 Matrix의 대괄호를 몇 개까지 뚫을 수 있느냐.\n",
    "* Shape는 Matrix의 대괄호를 하나씩 뚫을 때마다, 원소의 개수가 몇개 있느냐.\n",
    "\n",
    "#### ex) [[[1, 2, 4], [2, 3, 5]], [[1, 7, 4], [2, 3, 6]]]는 Rank가 3, Shape는 [2, 2, 3]\n",
    "\n",
    "#### dtype은 해당 텐서에 담긴 요소들의 자료형. ex) string, float, int 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(20)\n",
    "\n",
    "### Add two tensors\n",
    "c = tf.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과를 보면, 상수 텐서 두 개가 더해지지 않았는데, 이는 Tensorflow가 그래프 생성과 실행이 코드에서 분리되어 있기 때문이다.\n",
    "#### 그래프는 텐서들의 연산 모음.\n",
    "#### 텐서와 텐서들의 연산들을 코드에서 미리 정의하여 그래프를 만듬. &rarr; 연산을 실행하는 코드를 넣어 원하는 시점에 실제 연산을 수행.\n",
    "#### 이러한 연산 방식을 지연 실행(Lazy Evaluation)이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그래프의 연산 실행은 Session 안에서 이뤄져야 하며, Session 객체와 run 메서드를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n",
      "[10, 20, 30]\n"
     ]
    }
   ],
   "source": [
    "### Make Session instance\n",
    "sess = tf.Session()\n",
    "\n",
    "### Run Session\n",
    "print(sess.run(hello))\n",
    "print(sess.run([a, b, c]))\n",
    "\n",
    "### Close the Session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Placeholder와 Variable\n",
    "\n",
    "* Placeholder: 그래프에 사용할 **입력값을 나중에 받기 위해 사용**하는 매개변수.\n",
    "* Variable: 그래프를 최적화하는 용도로, Tensorflow의 학습 함수들이 **학습 결과를 갱신하기 위해 사용**하는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### None means that size is undetermined\n",
    "X = tf.placeholder(tf.float32, [None, 3])\n",
    "print(X)\n",
    "\n",
    "### Future input data\n",
    "x_data = [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X는 Placeholder로 나중에 training set을 넣을 자료로 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define variable\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "### You can define W implicitly like\n",
    "### W = tf.Variable([[0.1, 0.1], [0.1, 0.2], [0.2, 0.3]])\n",
    "b = tf.Variable(tf.random_normal([2, 1]))\n",
    "\n",
    "### Define operation expression\n",
    "### Matirx multiplication: X * W + b\n",
    "expr = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random_normal은 정규분포의 임의의 값으로 초기화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- x_data ---\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "--- W ---\n",
      "[[ 1.6845267  -0.7097309 ]\n",
      " [ 1.7618015   0.59761894]\n",
      " [ 1.472614    0.07079584]]\n",
      "--- b ---\n",
      "[[-0.5572125]\n",
      " [ 0.5276721]]\n",
      "--- expr ---\n",
      "[[ 9.068759    0.14068198]\n",
      " [24.91047     1.1016183 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "### Initialize variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"--- x_data ---\")\n",
    "print(x_data)\n",
    "print(\"--- W ---\")\n",
    "print(sess.run(W))\n",
    "print(\"--- b ---\")\n",
    "print(sess.run(b))\n",
    "print(\"--- expr ---\")\n",
    "### Link placeholder X with pre-defined x_data\n",
    "print(sess.run(expr, feed_dict = {X: x_data}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global_variables_initializer는 앞에서 정의한 변수들을 초기화하는 함수이다. 변수를 처음 실행하는 것이라면, 연산을 실행하기 전에 반드시 이 함수를 호출한다.\n",
    "\n",
    "#### feed_dict 매개변수는 그래프를 실행할 때 사용할 입력값을 지정한다. Placeholder X에 미리 정의해둔 x_data를 넣어준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 선형 회귀 모델 구현하기\n",
    "\n",
    "#### 선형 회귀: 주어진 x와 y 값을 가지고 서로 간의 관계를 파악한 뒤에, 새로운 x 값에 대한 y 값을 예측하는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Sets\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize weight & bias randomly in the uniform distribution\n",
    "W = tf.Variable(tf.random_uniform([1], -1, 1))\n",
    "b = tf.Variable(tf.random_uniform([1], -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### Placeholders\n",
    "X = tf.placeholder(tf.float32, name = \"X\")\n",
    "Y = tf.placeholder(tf.float32, name = \"Y\")\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholder의 name 매개변수로 플레이스홀더의 이름을 설정할 수 있다. name이 없어도 자동으로 이름은 부여된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear hypothesis function\n",
    "hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W와 X가 아직 행렬이 아니므로, matmul 메소드가 아닌 기본 곱셈 연산자를 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cost Function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가설 함수값과 실제값의 차이를 제곱하여 평균한 것을 Cost Function으로 삼겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경사하강법은 함수의 기울기를 구하고 기울기가 낮은 쪽으로 계속 이동시키면서 최적의 값을 찾아 나가는 방법이다.\n",
    "#### 학습률은 얼마나 빠르게 이동시킬 것인가를 설정하는 값이다. &rarr; 학습을 진행하는 과정에 영향을 주는 변수를 hyperparameter(하이퍼파라미터)라 한다. 이것을 잘 튜닝하는 것 역시 큰 과제."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.909205 [1.309602] [-0.34144145]\n",
      "20 0.009113527 [1.108211] [-0.2459892]\n",
      "40 0.0034433426 [1.0665147] [-0.15120374]\n",
      "60 0.0013009881 [1.040885] [-0.09294134]\n",
      "80 0.0004915465 [1.0251311] [-0.05712883]\n",
      "100 0.0001857205 [1.0154475] [-0.03511575]\n",
      "120 7.0170136e-05 [1.0094951] [-0.02158478]\n",
      "140 2.6512205e-05 [1.0058365] [-0.01326773]\n",
      "160 1.0017253e-05 [1.0035875] [-0.00815533]\n",
      "180 3.7847187e-06 [1.0022051] [-0.00501287]\n",
      "200 1.4299598e-06 [1.0013554] [-0.00308127]\n",
      "220 5.402896e-07 [1.0008332] [-0.00189398]\n",
      "240 2.0411345e-07 [1.0005121] [-0.00116417]\n",
      "260 7.715153e-08 [1.0003148] [-0.00071562]\n",
      "280 2.9128396e-08 [1.0001935] [-0.00043983]\n",
      "300 1.0999771e-08 [1.000119] [-0.00027037]\n",
      "320 4.1567696e-09 [1.0000731] [-0.00016613]\n",
      "340 1.5655909e-09 [1.000045] [-0.00010204]\n",
      "360 5.954585e-10 [1.0000275] [-6.2703664e-05]\n",
      "380 2.2342898e-10 [1.0000169] [-3.8547885e-05]\n",
      "400 8.492407e-11 [1.0000105] [-2.374209e-05]\n",
      "420 3.193179e-11 [1.0000064] [-1.4618601e-05]\n",
      "440 1.2165676e-11 [1.0000039] [-9.023713e-06]\n",
      "460 4.6576076e-12 [1.0000024] [-5.5149862e-06]\n",
      "480 1.8059628e-12 [1.0000014] [-3.4407458e-06]\n",
      "500 6.6317324e-13 [1.000001] [-2.0897076e-06]\n",
      "520 2.5105842e-13 [1.0000006] [-1.2910053e-06]\n",
      "540 1.373716e-13 [1.0000005] [-8.697988e-07]\n",
      "560 4.8553755e-14 [1.0000004] [-6.5919585e-07]\n",
      "580 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "600 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "620 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "640 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "660 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "680 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "700 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "720 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "740 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "760 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "780 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "800 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "820 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "840 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "860 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "880 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "900 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "920 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "940 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "960 3.7895614e-14 [1.0000004] [-6.234331e-07]\n",
      "980 3.7895614e-14 [1.0000004] [-6.234331e-07]\n"
     ]
    }
   ],
   "source": [
    "### session block with \"with\" block\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        ## _ is assigned to train_op & cost_val is assigned to cost\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict = {X: x_data, Y: y_data})\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
